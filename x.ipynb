{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9872ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58716ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  label\n",
       "0                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "train_data = train_data.drop(columns=['id'])\n",
    "test_data = test_data.drop(columns=['id'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae705305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Number of null in data: 5\n",
      "Test\n",
      "Number of null in data: 3\n",
      "Train: (149995, 2), Test: (49997, 2)\n"
     ]
    }
   ],
   "source": [
    "# NaN 결측치 제거\n",
    "def get_null_index(df):\n",
    "    null_index = df.loc[df.isnull().sum(1) > 0].index\n",
    "    print(f'Number of null in data: {len(null_index)}')\n",
    "    return null_index\n",
    "\n",
    "print('Train')\n",
    "train_null_index = get_null_index(train_data)\n",
    "print('Test')\n",
    "test_null_index = get_null_index(test_data)\n",
    "\n",
    "train_data = train_data.drop(index=train_null_index)\n",
    "test_data = test_data.drop(index=test_null_index)\n",
    "\n",
    "print(f'Train: {train_data.shape}, Test: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "749fe022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before remove:\n",
      "Train duplicated data: 3656\n",
      "Test duplicated data: 793\n",
      "After remove:\n",
      "Train duplicated data: 0\n",
      "Test duplicated data: 0\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 중복 제거\n",
    "print('Before remove:')\n",
    "print(f'Train duplicated data: {train_data.duplicated().sum()}')\n",
    "print(f'Test duplicated data: {test_data.duplicated().sum()}')\n",
    "\n",
    "train_data = train_data.loc[~train_data.duplicated()].reset_index(drop=True)\n",
    "test_data = test_data.loc[~test_data.duplicated()].reset_index(drop=True)\n",
    "\n",
    "print('After remove:')\n",
    "print(f'Train duplicated data: {train_data.duplicated().sum()}')\n",
    "print(f'Test duplicated data: {test_data.duplicated().sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d74e6e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['영화', '재밌', '네요']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "txt = '영화 재밌네요'\n",
    "# 형태소로 토큰화\n",
    "print(tokenizer.morphs(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a38baeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 53979\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "def load_data_with_tokenization(df):\n",
    "    X = df['document'].apply(tokenizer.morphs)\n",
    "    y = df['label'].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "x_train, y_train = load_data_with_tokenization(train_data)\n",
    "x_test, y_test = load_data_with_tokenization(test_data)\n",
    "\n",
    "# create vocabulary\n",
    "VOCAB2INDEX = {}\n",
    "VOCAB2INDEX['[PAD]'] = 0\n",
    "VOCAB2INDEX['[UNK]'] = 1\n",
    "unique_tokens = set()  # to get non_duplicate tokens\n",
    "for s in x_train:\n",
    "    unique_tokens.update(set(s))\n",
    "print(f'Number of unique tokens: {len(unique_tokens)}')\n",
    "\n",
    "for index, token in enumerate(unique_tokens, 2):\n",
    "    VOCAB2INDEX[token] = index\n",
    "INDEX2VOCAB = list(VOCAB2INDEX.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to vocab2index\n",
    "def encode(tokens):\n",
    "    idx_tokens = []\n",
    "    for token in tokens:\n",
    "        if VOCAB2INDEX.get(token) is None:\n",
    "            idx = VOCAB2INDEX['[UNK]']\n",
    "        else:\n",
    "            idx = VOCAB2INDEX[token]\n",
    "        idx_tokens.append(idx)\n",
    "    return idx_tokens\n",
    "\n",
    "def decode(idx_tokens, keep_pad=False):\n",
    "    tokens = []\n",
    "    for idx in idx_tokens:\n",
    "        token = INDEX2VOCAB[idx]\n",
    "        if not keep_pad and token == '[PAD]':\n",
    "            continue\n",
    "        tokens.append(token)\n",
    "    return ''.join(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aiffel2022-0SDAWiwa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1a1b9479b242366efcd00035e60f2e24dbc2c54df35946856cbb4607e74fc36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
